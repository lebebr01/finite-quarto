---
title: 'simglm v0.9.23: Propensity Score Modeling'
author: Brandon LeBeau
date: '2025-10-06'
categories:
  - R
  - simglm
  - modeling
  - propensity scores
---

```{r}
#| echo: false
#| warning: false
#| message: false
library(ggplot2)
theme_set(theme_bw(base_size = 14))
```

#

Building on last week’s post about [propensity score simulation](/posts/2025-09-24-simglm-propensity.qmd), the `simglm` package has been extended to now allow for the estimation of power in addition to the propensity score simulations. Recall, propensity scores can be helpful for causal inference with intact groups, when random assignment was either not possible or not done. This allows for the estimation of power under all three supported propensity score methods:    

+ Covariate adjustment
+ Inverse propensity score weighting
+ Stabilized propensity score weighting

One nice feature is that no additional simulation arguments are needed to handle the model fitting and replication procedures. These pass directly from the previous functionality handled from within the package. One small adjustment was made internally to allow for the inclusion of the propensity score covariate when that option is specified. Since this term is not usually of substantive value, it can be filtered out from the final output as well. 

If you haven't already, remember to first install the simglm package from GitHub. 
```{r}
#| eval: false
remotes::install_github('lebebr01/simglm')
```

## Fitting a covariate adjusted model. 

The below code does the following steps:  

1. Simulates the data with the propensity model. That is, the treatment attribute is simulated as a function of age and SES so that those that are older and higher SES are more likely to be in the treatment group.  
2. Simulates the full model to generate scores for student achievement.  
3. Fit propensity score model to the simulated data.  
4. Fit the final model, with the estimated propensity scores included as a covariate, and store model estimates.   
5. Repeat steps 1–4 for 500 replications (illustrative only; use more in practice).

To fit the propensity score adjusted covariate model, `propensity_type = 'covariate'` is added to the propensity model simulation arguments. 

```{r}
library(simglm)

sim_arguments <- list(
    formula = achievement ~ 1 + motivation + trt + age + ses,
    fixed = list(
        motivation = list(var_type = 'continuous',
                           mean = 0, sd = 20)
    ),
    sample_size = 1000,
    error = list(variance = 10),
    reg_weights = c(50, 0.4, 1.2, 0.1, 0.25),
    propensity = list(
        formula = trt ~ 1 + age + ses,
        fixed = list(age = list(var_type = 'ordinal', 
                         levels = -7:7),
                     ses = list(var_type = 'continuous', 
                         mean = 0, sd = 5)),
        sample_size = 1000,
        error = list(variance = 5),
        reg_weights = c(2, 0.3, -0.5),
        outcome_type = 'binary'
    ),
    model_fit = list(formula = achievement ~ 1 + motivation + trt + age + ses,
                   model_function = 'lm'),
    propensity_model = list(
        formula = trt ~ 1 + age + ses,
        propensity_type = 'covariate'
    ),
    replications = 500,
    extract_coefficients = TRUE
)
replicate_simulation(sim_arguments) |>
  compute_statistics(sim_arguments, alternative_power = FALSE, 
                     type_1_error = FALSE)
```


## Fitting a IPW adjusted model. 

The below code does the following steps:  

1. Simulates the data with the propensity model. That is, the treatment attribute is simulated as a function of age and SES so that those that are older and higher SES are more likely to be in the treatment group.   
2. Simulates the full model to generate scores for student achievement.  
3. Fit the propensity score model to the simulated data.  
4. Fit the final model, using inverse propensity score weighting, and store model estimates.   
5. Repeat steps 1–4 for 500 replications (illustrative only; use more in practice).  

The only addition needed is to add, `propensity_type = 'ipw'` to the propensity model simulation arguments. 

```{r}
sim_arguments <- list(
    formula = achievement ~ 1 + motivation + trt + age + ses,
    fixed = list(
        motivation = list(var_type = 'continuous',
                           mean = 0, sd = 20)
    ),
    sample_size = 1000,
    error = list(variance = 10),
    reg_weights = c(50, 0.4, 1.2, 0.1, 0.25),
    propensity = list(
        formula = trt ~ 1 + age + ses,
        fixed = list(age = list(var_type = 'ordinal', 
                         levels = -7:7),
                     ses = list(var_type = 'continuous', 
                         mean = 0, sd = 5)),
        sample_size = 1000,
        error = list(variance = 5),
        reg_weights = c(2, 0.3, -0.5),
        outcome_type = 'binary'
    ),
    model_fit = list(formula = achievement ~ 1 + motivation + trt + age + ses,
                   model_function = 'lm'),
    propensity_model = list(
        formula = trt ~ 1 + age + ses,
        propensity_type = 'ipw'
    ),
    replications = 500,
    extract_coefficients = TRUE
)
replicate_simulation(sim_arguments) |>
  compute_statistics(sim_arguments, alternative_power = FALSE, 
                     type_1_error = FALSE)
```

## Fitting a SBW adjusted model. 

The code below performs the following steps.

1. Simulates the data with the propensity model. That is, the treatment attribute is simulated as a function of age and SES so that those that are older and higher SES are more likely to be in the treatment group. 
2. Simulates the full model to generate scores for student achievement.
3. Fit the propensity score model to the simulated data
4. Fit the final model, using stabilized propensity score weighting, and store model estimates. 
5. Repeat steps 1–4 for 500 replications (illustrative only; use more in practice).

The only addition needed is to add, `propensity_type = 'sbw'` to the propensity model simulation arguments. 

```{r}
sim_arguments <- list(
    formula = achievement ~ 1 + motivation + trt + age + ses,
    fixed = list(
        motivation = list(var_type = 'continuous',
                           mean = 0, sd = 20)
    ),
    sample_size = 1000,
    error = list(variance = 10),
    reg_weights = c(50, 0.4, 1.2, 0.1, 0.25),
    propensity = list(
        formula = trt ~ 1 + age + ses,
        fixed = list(age = list(var_type = 'ordinal', 
                         levels = -7:7),
                     ses = list(var_type = 'continuous', 
                         mean = 0, sd = 5)),
        sample_size = 1000,
        error = list(variance = 5),
        reg_weights = c(2, 0.3, -0.5),
        outcome_type = 'binary'
    ),
    model_fit = list(formula = achievement ~ 1 + motivation + trt + age + ses,
                   model_function = 'lm'),
    propensity_model = list(
        formula = trt ~ 1 + age + ses,
        propensity_type = 'sbw'
    ),
    replications = 500,
    extract_coefficients = TRUE
)
replicate_simulation(sim_arguments) |>
  compute_statistics(sim_arguments, alternative_power = FALSE, 
                     type_1_error = FALSE)
```

## Comparing model estimates with and without propensity scores.

As a final example, let's see what happens when we generate data with propensity scores, but do not account for this within the model fitting. To omit the propensity scores being fitted, the `propensity_model` simulation arguments can be omitted. I'm fitting three different types of models to this:

+ The full model, including a propensity score analysis using stabilized propensity weights.
+ The full model without any propensity score analysis, but statistically adjusting for the observed covariates used in the propensity score model.
+ A reduced, misspecified model that omits age and SES and does not include a propensity score model.

The last misspecified model should produce an average treatment effect that is severely biased as the treatment group was not random, instead, the treatment group specification was a function of age and SES.


```{r}
#| code-fold: true
sim_arguments <- list(
    formula = achievement ~ 1 + motivation + trt + age + ses,
    fixed = list(
        motivation = list(var_type = 'continuous',
                           mean = 0, sd = 20)
    ),
    sample_size = 1000,
    error = list(variance = 10),
    reg_weights = c(50, 0.4, 1.2, 0.1, 0.25),
    propensity = list(
        formula = trt ~ 1 + age + ses,
        fixed = list(age = list(var_type = 'ordinal', 
                         levels = -7:7),
                     ses = list(var_type = 'continuous', 
                         mean = 0, sd = 5)),
        sample_size = 1000,
        error = list(variance = 5),
        reg_weights = c(2, 0.3, -0.5),
        outcome_type = 'binary'
    ),
    model_fit = list(formula = achievement ~ 1 + motivation + trt + age + ses,
                   model_function = 'lm'),
    replications = 500,
    extract_coefficients = TRUE
)
no_propensity <- replicate_simulation(sim_arguments) |>
    dplyr::bind_rows() |>
    dplyr::mutate(group = 'no_prop')

sim_arguments <- list(
    formula = achievement ~ 1 + motivation + trt + age + ses,
    fixed = list(
        motivation = list(var_type = 'continuous',
                           mean = 0, sd = 20)
    ),
    sample_size = 1000,
    error = list(variance = 10),
    reg_weights = c(50, 0.4, 1.2, 0.1, 0.25),
    propensity = list(
        formula = trt ~ 1 + age + ses,
        fixed = list(age = list(var_type = 'ordinal', 
                         levels = -7:7),
                     ses = list(var_type = 'continuous', 
                         mean = 0, sd = 5)),
        sample_size = 1000,
        error = list(variance = 5),
        reg_weights = c(2, 0.3, -0.5),
        outcome_type = 'binary'
    ),
    model_fit = list(formula = achievement ~ 1 + motivation + trt,
                   model_function = 'lm'),
    replications = 500,
    extract_coefficients = TRUE
)
missspec <- replicate_simulation(sim_arguments) |>
    dplyr::bind_rows() |>
    dplyr::mutate(group = 'miss_spec')

sim_arguments <- list(
    formula = achievement ~ 1 + motivation + trt + age + ses,
    fixed = list(
        motivation = list(var_type = 'continuous',
                           mean = 0, sd = 20)
    ),
    sample_size = 1000,
    error = list(variance = 10),
    reg_weights = c(50, 0.4, 1.2, 0.1, 0.25),
    propensity = list(
        formula = trt ~ 1 + age + ses,
        fixed = list(age = list(var_type = 'ordinal', 
                         levels = -7:7),
                     ses = list(var_type = 'continuous', 
                         mean = 0, sd = 5)),
        sample_size = 1000,
        error = list(variance = 5),
        reg_weights = c(2, 0.3, -0.5),
        outcome_type = 'binary'
    ),
    model_fit = list(formula = achievement ~ 1 + motivation + trt + age + ses,
                   model_function = 'lm'),
    propensity_model = list(
        formula = trt ~ 1 + age + ses,
        propensity_type = 'sbw'
    ),
    replications = 500,
    extract_coefficients = TRUE
)
sbw_propensity <- replicate_simulation(sim_arguments) |>
    dplyr::bind_rows() |>
    dplyr::mutate(group = 'sbw')
```

Let's visualize the differences across the three methods, with a vertical line at the specified population treatment effect. You can see that when nothing is done with the misspecified model, the estimated treatment effect is biased severely. The simple covariate adjusted effect without fitting the propensity score model produces an estimated effect similar to the specified population treatment effect, but may slightly underestimate variance. Finally, the propensity score model with the stabilized propensity score weighting produces an unbiased treatment effect and may produce a more accurate picture of variability in this treatment effect. 

```{r}
sbw_propensity |> 
    dplyr::bind_rows(no_propensity)|> 
    dplyr::bind_rows(missspec) |>
    dplyr::filter(term == 'trt') |> 
    ggformula::gf_density(~estimate, fill = ~ group) |> 
    ggformula::gf_vline(xintercept = ~ 1.2)
```

These examples show how simglm can be used not only to simulate propensity score models but also to estimate power under different adjustment strategies. By simulating under known conditions, you can evaluate the robustness of your causal modeling choices before applying them to real data. Because these same simulations can also track significance rates across replications, you can easily extend them to estimate statistical power under different adjustment strategies.


```{r}
#| code-fold: true
sessionInfo()
```